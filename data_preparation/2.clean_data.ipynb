{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10e38ff9",
   "metadata": {},
   "source": [
    "# Clean Data\n",
    "\n",
    "This notebook processes and cleans parsed news article data.  \n",
    "\n",
    "The main steps are:\n",
    "\n",
    "1. **Standardizing values** (text cleaning, formatting, and handling missing data)\n",
    "2. **Filtering** (removing short articles and unwanted titles)\n",
    "3. **Deduplication** (exact matches and near-duplicates)\n",
    "4. **Final clean-up** (column selection, reordering, and saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ff60e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from ftfy import fix_text\n",
    "import pickle\n",
    "\n",
    "from utils import standardize_text, add_duplicate_flags\n",
    "\n",
    "# Input and output paths\n",
    "input_path = \"../data/processed/parsed_articles.pkl\"\n",
    "output_path = \"../data/processed/cleaned_articles.pkl\"\n",
    "\n",
    "# Load data\n",
    "df_articles = pd.read_pickle(input_path)\n",
    "\n",
    "# number of articles expected\n",
    "expected_n_articles = 500 * 86 + 305 + 361\n",
    "\n",
    "# Tracking summary counts\n",
    "summary = []\n",
    "def log_count(step_name, before, after):\n",
    "    summary.append({\n",
    "        \"Step\": step_name,\n",
    "        \"Before\": before,\n",
    "        \"After\": after,\n",
    "        \"Dropped\": before - after\n",
    "    })\n",
    "    \n",
    "# Record initial load\n",
    "summary.append({\n",
    "    \"Step\": \"Initial load\",\n",
    "    \"Before\": expected_n_articles,\n",
    "    \"After\": df_articles.shape[0],\n",
    "    \"Dropped\": df_articles.shape[0] - expected_n_articles\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76054cad",
   "metadata": {},
   "source": [
    "## 1. Standardize Values\n",
    "\n",
    "Here we:\n",
    "\n",
    "* Fill missing values in key columns\n",
    "* Convert article length to integers\n",
    "* Clean text fields (normalize whitespace, fix broken characters, fix text with ftfy)\n",
    "* Standardize titles (remove punctuation and stop words)\n",
    "* Remove trailing \"Load-Date\" metadata from article bodies\n",
    "* Group publishers into consistent categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72288682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load title stop words\n",
    "with open(\"title_stop_words.pkl\", \"rb\") as f:\n",
    "    title_stop_words = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0951543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(u'\\xa0', u' ')\n",
    "    return fix_text(text).strip(\" \\n\")\n",
    "\n",
    "def remove_load_date(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove 'Load-Date: <Month day, year>' if present at the end of the text.\n",
    "    \"\"\"\n",
    "    # Regex: match optional whitespace, then 'Load-Date:', then date, till the very end\n",
    "    pattern = r'\\s*Load-Date:\\s+[A-Za-z]+\\s+\\d{1,2},\\s+\\d{4}\\s*$'\n",
    "    return re.sub(pattern, '', text)\n",
    "    \n",
    "def convert_length(length): # see Guo code\n",
    "    length = int(length.strip(\" \")[:-6])\n",
    "    return length\n",
    "\n",
    "def obtain_publisher_group(source_file):\n",
    "    folder = os.path.dirname(source_file)\n",
    "    if folder == \"NYT\":\n",
    "        return \"New York Times\"\n",
    "    elif folder == \"Other publishers\":\n",
    "        return \"Other publisher\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown publisher group for folder: {folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f411ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "df_articles[\"section\"] = df_articles[\"section\"].fillna(\"\") \n",
    "df_articles[\"length\"] = df_articles[\"length\"].fillna(\"0 words\")\n",
    "\n",
    "# Convert length string to integer\n",
    "df_articles[\"length\"] = df_articles[\"length\"].apply(convert_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b028778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text columns\n",
    "txt_cols = ['title', 'publisher', 'section', 'body']\n",
    "for txt_col in txt_cols:\n",
    "    df_articles[txt_col] = df_articles[txt_col].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "592167f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize titles\n",
    "df_articles['title_stand'] = df_articles['title'].apply(lambda x: standardize_text(x, title_stop_words))\n",
    "\n",
    "# Remove trailing load date\n",
    "df_articles['body'] = df_articles['body'].apply(remove_load_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83739dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign publisher group\n",
    "df_articles['publisher_group'] = df_articles['source_file'].apply(obtain_publisher_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61ee0eb",
   "metadata": {},
   "source": [
    "## 2. Filters\n",
    "\n",
    "We filter articles to:\n",
    "* Remove very short articles (fewer than 100 words)\n",
    "* Exclude recurring recommendation list titles\n",
    "* Remove articles whose titles start with specific patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f63fc490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting number of articles: 43666.\n"
     ]
    }
   ],
   "source": [
    "# Initial count\n",
    "before = df_articles.shape[0]\n",
    "print(f\"Starting number of articles: {before}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "952ae429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 109 articles. Net number of articles: 43557\n"
     ]
    }
   ],
   "source": [
    "# Filter 1: Minimum length\n",
    "df_articles = df_articles.loc[df_articles['length'] >= 100]\n",
    "after = df_articles.shape[0]\n",
    "log_count(\"Filter: Min length ≥ 100 words\", before, after)\n",
    "print(f\"Dropped {before - after} articles. Net number of articles: {df_articles.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c919df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter 2: Specific titles\n",
    "titles_reccomendation_lists = ['new & noteworthy paperbacks',\n",
    "                             'paperback row',\n",
    "                             'art',\n",
    "                             'four stars: superior. three stars: good. two stars: average. one star: poor. d (',\n",
    "                             'movie guide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1addb9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 292 articles. Net number of articles: 43265\n"
     ]
    }
   ],
   "source": [
    "df_articles = df_articles.loc[~df_articles['title'].str.lower().isin(titles_reccomendation_lists)]\n",
    "before = after\n",
    "after = df_articles.shape[0]\n",
    "log_count(\"Filter: Exact title match list\", before, after)\n",
    "print(f\"Dropped {before - after} articles. Net number of articles: {df_articles.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45d444b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 241 articles. Net number of articles: 43024\n"
     ]
    }
   ],
   "source": [
    "# Filter 3: Titles starting with certain patterns\n",
    "startswith_filter = ('best sellers:', 'four stars:')\n",
    "df_articles = df_articles[\n",
    "    ~df_articles['title'].str.lower().str.startswith(startswith_filter)\n",
    "]\n",
    "before = after\n",
    "after = df_articles.shape[0]\n",
    "log_count(\"Filter: Title startswith patterns\", before, after)\n",
    "print(f\"Dropped {before - after} articles. Net number of articles: {df_articles.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3157ab",
   "metadata": {},
   "source": [
    "## 3. Deduplication\n",
    "\n",
    "We remove:\n",
    "* **Exact duplicates** (keeping earliest date)\n",
    "* **Near-duplicates** (based on match in standardardized title and body similarity score above 90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf7fd63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 551 articles. Net number of articles: 42473\n"
     ]
    }
   ],
   "source": [
    "# Exact duplicates\n",
    "# Shuffle for randomness\n",
    "df_articles = df_articles.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Sort by date and drop duplicates\n",
    "df_articles = (\n",
    "    df_articles\n",
    "    .sort_values(by='date', ascending=True)\n",
    "    .drop_duplicates(subset=[\"body\", \"title\"], keep='first')\n",
    ")\n",
    "\n",
    "before = after\n",
    "after = df_articles.shape[0]\n",
    "log_count(\"Deduplication: Exact matches\", before, after)\n",
    "print(f\"Dropped {before - after} articles. Net number of articles: {df_articles.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2142856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining near-duplicates flag for 0.9 threshold\n"
     ]
    }
   ],
   "source": [
    "# Near-duplicates\n",
    "thresholds = [0.90]\n",
    "df_articles = add_duplicate_flags(df_articles, \"title_stand\", thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b4ece3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1179 articles. Net number of articles: 41294\n"
     ]
    }
   ],
   "source": [
    "df_articles = df_articles.loc[~df_articles['is_near_duplicate_90']]\n",
    "before = after\n",
    "after = df_articles.shape[0]\n",
    "log_count(\"Deduplication: Near-duplicates (90%)\", before, after)\n",
    "print(f\"Dropped {before - after} articles. Net number of articles: {df_articles.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a259fbc0",
   "metadata": {},
   "source": [
    "## 4. Final Clean-up & Save\n",
    "\n",
    "We:\n",
    "* Keep only selected columns\n",
    "* Rename publisher group to publisher\n",
    "* (TODO) Separate letters to the editor\n",
    "* Sort data and reset index\n",
    "* Save cleaned DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98e72a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and rename columns\n",
    "cols = ['title', 'publisher_group', 'date', 'section', 'body', 'source_file']\n",
    "df_articles = df_articles[cols].rename(columns = {\"publisher_group\": \"publisher\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff9f53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Separate letters to the editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a8eed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and reset index\n",
    "df_articles = df_articles.sort_values(by='date', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d38d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "df_articles.to_pickle(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b83eff74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>section</th>\n",
       "      <th>body</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Under a Highway in Rio, a Dance Style Charms a...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>WORLD; americas</td>\n",
       "      <td>Trucks, buses and cars rumbled overhead, drown...</td>\n",
       "      <td>NYT/1.DOCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>These were the big stories in arts and culture...</td>\n",
       "      <td>Other publisher</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>WHAT TO KNOW</td>\n",
       "      <td>The arts in Dayton continued to thrive in 2024...</td>\n",
       "      <td>Other publishers/Files (500) (1).DOCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She Exalted The Beauty Of Dance</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Section C; Column 0; The Arts/Cultural Desk; P...</td>\n",
       "      <td>She was The New Yorker's first dance critic. H...</td>\n",
       "      <td>NYT/1.DOCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Well-Documented Childhood. A Very Private Life.</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Section A; Column 0; National Desk; Pg. 16</td>\n",
       "      <td>Jimmy Carter's daughter had an extraordinary a...</td>\n",
       "      <td>NYT/1.DOCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Congressional pay, minimum wage stagnant for y...</td>\n",
       "      <td>Other publisher</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>OPINION; Pg. A13</td>\n",
       "      <td>ABSTRACT\\nMembers of Congress have not seen a ...</td>\n",
       "      <td>Other publishers/Files (500) (1).DOCX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        publisher  \\\n",
       "0  Under a Highway in Rio, a Dance Style Charms a...   New York Times   \n",
       "1  These were the big stories in arts and culture...  Other publisher   \n",
       "2                    She Exalted The Beauty Of Dance   New York Times   \n",
       "3  A Well-Documented Childhood. A Very Private Life.   New York Times   \n",
       "4  Congressional pay, minimum wage stagnant for y...  Other publisher   \n",
       "\n",
       "         date                                            section  \\\n",
       "0  2024-12-31                                    WORLD; americas   \n",
       "1  2024-12-31                                       WHAT TO KNOW   \n",
       "2  2024-12-31  Section C; Column 0; The Arts/Cultural Desk; P...   \n",
       "3  2024-12-31         Section A; Column 0; National Desk; Pg. 16   \n",
       "4  2024-12-31                                   OPINION; Pg. A13   \n",
       "\n",
       "                                                body  \\\n",
       "0  Trucks, buses and cars rumbled overhead, drown...   \n",
       "1  The arts in Dayton continued to thrive in 2024...   \n",
       "2  She was The New Yorker's first dance critic. H...   \n",
       "3  Jimmy Carter's daughter had an extraordinary a...   \n",
       "4  ABSTRACT\\nMembers of Congress have not seen a ...   \n",
       "\n",
       "                             source_file  \n",
       "0                             NYT/1.DOCX  \n",
       "1  Other publishers/Files (500) (1).DOCX  \n",
       "2                             NYT/1.DOCX  \n",
       "3                             NYT/1.DOCX  \n",
       "4  Other publishers/Files (500) (1).DOCX  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview\n",
    "df_articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a88b6b3",
   "metadata": {},
   "source": [
    "# 5. Summary Table of Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37bfbf5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "      <th>Dropped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Initial load</td>\n",
       "      <td>43666</td>\n",
       "      <td>43666</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Filter: Min length ≥ 100 words</td>\n",
       "      <td>43666</td>\n",
       "      <td>43557</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Filter: Exact title match list</td>\n",
       "      <td>43557</td>\n",
       "      <td>43265</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Filter: Title startswith patterns</td>\n",
       "      <td>43265</td>\n",
       "      <td>43024</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deduplication: Exact matches</td>\n",
       "      <td>43024</td>\n",
       "      <td>42473</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deduplication: Near-duplicates (90%)</td>\n",
       "      <td>42473</td>\n",
       "      <td>41294</td>\n",
       "      <td>1179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Step  Before  After  Dropped\n",
       "0                          Initial load   43666  43666        0\n",
       "1        Filter: Min length ≥ 100 words   43666  43557      109\n",
       "2        Filter: Exact title match list   43557  43265      292\n",
       "3     Filter: Title startswith patterns   43265  43024      241\n",
       "4          Deduplication: Exact matches   43024  42473      551\n",
       "5  Deduplication: Near-duplicates (90%)   42473  41294     1179"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(summary)\n",
    "display(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
